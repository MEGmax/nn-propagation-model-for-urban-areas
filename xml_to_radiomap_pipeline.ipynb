{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fa7222d",
   "metadata": {},
   "source": [
    "\n",
    "# XML â†’ Radio Map Dataset Pipeline\n",
    "\n",
    "This notebook converts a **Mitsuba XML scene** into training-ready tensors with the exact contract:\n",
    "\n",
    "- **rss**: `(1, H, W)` float32, normalized to ~[-1, 1]\n",
    "- **cond**: `(C_cond, H, W)` float32, with **elevation as channel 0**\n",
    "- **elevation**: `(H, W)` float32 (also included in `cond[0]`)\n",
    "\n",
    "Saved as a dict via `np.save(...).item()` with keys:\n",
    "`'rss'`, `'cond'`, `'elevation'`.\n",
    "\n",
    "The notebook is parameterized by the XML path.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed426fa4",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2214a80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- USER PARAMETERS ----\n",
    "XML_PATH = \"/Users/matthewgrech/ECE2T5 1st Sem/ECE496/Diffusion/scene_generation/studio_setup.xml\"          # Path to Mitsuba XML\n",
    "MESH_ROOT = \"/Users/matthewgrech/ECE2T5 1st Sem/ECE496/Diffusion/scene_generation\"                 # Root directory for mesh files\n",
    "H, W = 128, 128                  # Output grid resolution\n",
    "RSS_DB_FLOOR = -100.0            # dB floor for normalization\n",
    "RSS_DB_SCALE = 50.0              # scale for normalization\n",
    "OUTPUT_PATH = \"sample.npy\"      # Output sample file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1824db",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4dd1cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58f8faf",
   "metadata": {},
   "source": [
    "## XML Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60c79139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 15 shapes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def parse_scene_xml(xml_path):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Materials\n",
    "    material_map = {}\n",
    "    for i, bsdf in enumerate(root.findall(\"bsdf\")):\n",
    "        material_map[bsdf.attrib[\"id\"]] = i\n",
    "\n",
    "    shapes = []\n",
    "    for shape in root.findall(\"shape\"):\n",
    "        filename = shape.find(\"string[@name='filename']\").attrib[\"value\"]\n",
    "        bsdf_ref = shape.find(\"ref\").attrib[\"id\"]\n",
    "\n",
    "        shapes.append({\n",
    "            \"mesh\": filename,\n",
    "            \"material_id\": material_map[bsdf_ref],\n",
    "            \"semantic\": 0 if \"Plane\" in filename else 1  # 0=ground, 1=building\n",
    "        })\n",
    "    return shapes, material_map\n",
    "\n",
    "shapes, material_map = parse_scene_xml(XML_PATH)\n",
    "print(f\"Loaded {len(shapes)} shapes\")    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bfee7d",
   "metadata": {},
   "source": [
    "## PLY Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80349689",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_ply(path):\n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    i = lines.index(\"end_header\\n\") + 1\n",
    "    header = lines[:i]\n",
    "\n",
    "    v_count = int([l for l in header if l.startswith(\"element vertex\")][0].split()[-1])\n",
    "    f_count = int([l for l in header if l.startswith(\"element face\")][0].split()[-1])\n",
    "\n",
    "    verts = np.array([list(map(float, l.split())) for l in lines[i:i+v_count]], dtype=np.float32)\n",
    "    faces = np.array([list(map(int, l.split()[1:])) for l in lines[i+v_count:i+v_count+f_count]], dtype=np.int32)\n",
    "\n",
    "    return verts, faces\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859e9319",
   "metadata": {},
   "source": [
    "## Rasterization Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2344068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rasterize_height(vertices, H, W):\n",
    "    # Simple orthographic projection to grid\n",
    "    xy = vertices[:, :2]\n",
    "    z = vertices[:, 2]\n",
    "\n",
    "    xy_min, xy_max = xy.min(axis=0), xy.max(axis=0)\n",
    "    xy_norm = (xy - xy_min) / (xy_max - xy_min + 1e-6)\n",
    "\n",
    "    xi = np.clip((xy_norm[:,0] * (W-1)).astype(int), 0, W-1)\n",
    "    yi = np.clip((xy_norm[:,1] * (H-1)).astype(int), 0, H-1)\n",
    "\n",
    "    elev = np.zeros((H, W), dtype=np.float32)\n",
    "    count = np.zeros((H, W), dtype=np.float32)\n",
    "\n",
    "    for x, y, zz in zip(xi, yi, z):\n",
    "        elev[y, x] += zz\n",
    "        count[y, x] += 1\n",
    "\n",
    "    elev /= np.maximum(count, 1.0)\n",
    "    return elev\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36b825b",
   "metadata": {},
   "source": [
    "## Build Elevation & Material Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e43d11ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xc1 in position 206: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m material_maps \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((material_channels, H, W), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m shapes:\n\u001b[0;32m----> 6\u001b[0m     V, F \u001b[38;5;241m=\u001b[39m \u001b[43mload_ply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMESH_ROOT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmesh\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     elev_map \u001b[38;5;241m=\u001b[39m rasterize_height(V, H, W)\n\u001b[1;32m      8\u001b[0m     elevation \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmaximum(elevation, elev_map)\n",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m, in \u001b[0;36mload_ply\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_ply\u001b[39m(path):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 3\u001b[0m         lines \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     i \u001b[38;5;241m=\u001b[39m lines\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_header\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      6\u001b[0m     header \u001b[38;5;241m=\u001b[39m lines[:i]\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/codecs.py:322\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;66;03m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m--> 322\u001b[0m     (result, consumed) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;66;03m# keep undecoded input until the next call\u001b[39;00m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m=\u001b[39m data[consumed:]\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xc1 in position 206: invalid start byte"
     ]
    }
   ],
   "source": [
    "\n",
    "elevation = np.zeros((H, W), dtype=np.float32)\n",
    "material_channels = len(material_map)\n",
    "material_maps = np.zeros((material_channels, H, W), dtype=np.float32)\n",
    "\n",
    "for s in shapes:\n",
    "    V, F = load_ply(Path(MESH_ROOT) / s[\"mesh\"])\n",
    "    elev_map = rasterize_height(V, H, W)\n",
    "    elevation = np.maximum(elevation, elev_map)\n",
    "    material_maps[s[\"material_id\"]] = np.maximum(material_maps[s[\"material_id\"]], elev_map > 0)\n",
    "\n",
    "# Normalize elevation to [0,1]\n",
    "elev_min, elev_max = elevation.min(), elevation.max()\n",
    "elevation_norm = (elevation - elev_min) / (elev_max - elev_min + 1e-6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0269de",
   "metadata": {},
   "source": [
    "## Transmitter Heatmap (Example: Single TX at Center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901de59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yy, xx = np.meshgrid(np.arange(H), np.arange(W), indexing='ij')\n",
    "tx_y, tx_x = H // 2, W // 2\n",
    "sigma = 10.0\n",
    "tx_heatmap = np.exp(-((xx - tx_x)**2 + (yy - tx_y)**2) / (2 * sigma**2)).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e3db11",
   "metadata": {},
   "source": [
    "## Assemble cond Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60061683",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cond = np.concatenate(\n",
    "    [\n",
    "        elevation_norm[None, ...],        # channel 0\n",
    "        tx_heatmap[None, ...],             # channel 1\n",
    "        material_maps                      # material one-hot channels\n",
    "    ],\n",
    "    axis=0\n",
    ").astype(np.float32)\n",
    "\n",
    "print(\"cond shape:\", cond.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62aed595",
   "metadata": {},
   "source": [
    "## Generate RSS Target (Placeholder / Simulator Hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedb4bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Placeholder RSS map (replace with Mitsuba/Sionna output)\n",
    "rss_db = -30.0 * tx_heatmap  # dummy signal decay\n",
    "rss_db = rss_db.astype(np.float32)\n",
    "\n",
    "rss_norm = (rss_db + abs(RSS_DB_FLOOR)) / RSS_DB_SCALE\n",
    "rss_norm = np.clip(rss_norm, -1.0, 1.0)\n",
    "\n",
    "rss = rss_norm[None, ...].astype(np.float32)\n",
    "print(\"rss shape:\", rss.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f42ebeb",
   "metadata": {},
   "source": [
    "## Save Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69218e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample = {\n",
    "    \"rss\": rss,\n",
    "    \"cond\": cond,\n",
    "    \"elevation\": elevation_norm.astype(np.float32)\n",
    "}\n",
    "\n",
    "np.save(OUTPUT_PATH, sample)\n",
    "print(f\"Saved sample to {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383b3b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Produce multiple samples for training ----\n",
    "OUTPUT_DIR = 'dataset_samples'\n",
    "NUM_SAMPLES = 64\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "for i in range(NUM_SAMPLES):\n",
    "    # randomize a transmitter location and small elevation perturbation\n",
    "    tx_y = np.random.randint(0, H)\n",
    "    tx_x = np.random.randint(0, W)\n",
    "    sigma = 8.0 + np.random.rand()*6.0\n",
    "    yy, xx = np.meshgrid(np.arange(H), np.arange(W), indexing='ij')\n",
    "    tx_heatmap = np.exp(-((xx - tx_x)**2 + (yy - tx_y)**2) / (2 * sigma**2)).astype(np.float32)\n",
    "    # simple placeholder RSS (replace with simulator output when available)\n",
    "    rss_db = -30.0 * tx_heatmap + np.random.randn(H, W).astype(np.float32) * 2.0\n",
    "    rss_norm = (rss_db + abs(RSS_DB_FLOOR)) / RSS_DB_SCALE\n",
    "    rss_norm = np.clip(rss_norm, -1.0, 1.0)\n",
    "    rss = rss_norm[None, ...].astype(np.float32)\n",
    "    # assemble cond: elevation first, then tx heatmap and material maps\n",
    "    cond = np.concatenate([elevation_norm[None, ...], tx_heatmap[None, ...], material_maps], axis=0).astype(np.float32)\n",
    "    sample = {'rss': rss, 'cond': cond, 'elevation': elevation_norm.astype(np.float32)}\n",
    "    fn = os.path.join(OUTPUT_DIR, f'sample_{i:04d}.npy')\n",
    "    np.save(fn, sample)\n",
    "print(f'Wrote {NUM_SAMPLES} samples to {OUTPUT_DIR}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280b4361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Quick train run using interm_demo.py ----\n",
    "import sys\n",
    "sys.path.insert(0, '.')  # ensure local imports work\n",
    "from interm_demo import TimeCondUNet, RadioMapDataset, train\n",
    "# build filenames list\n",
    "filenames = sorted([f for f in os.listdir(OUTPUT_DIR) if f.endswith('.npy')])\n",
    "ds = RadioMapDataset(OUTPUT_DIR, filenames)\n",
    "# infer cond channels from first sample\n",
    "tmp = np.load(os.path.join(OUTPUT_DIR, filenames[0]), allow_pickle=True).item()\n",
    "cond_channels = tmp['cond'].shape[0]\n",
    "print('Detected cond channels =', cond_channels)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = TimeCondUNet(in_ch=1, cond_channels=cond_channels, base_ch=32, channel_mults=(1,2,4), num_res_blocks=2, time_emb_dim=128, cond_emb_dim=64)\n",
    "# small smoke-train (1 epoch) to verify everything wires up\n",
    "train(model, ds, device=device, epochs=1, batch_size=8, lr=2e-4, timesteps=200, save_every=1, out_dir='./tmp_ckpt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
